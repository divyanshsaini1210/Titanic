{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os\n",
      "/kaggle/input/titanic/gender_submission.csv\n",
      "/kaggle/input/titanic/test.csv\n",
      "/kaggle/input/titanic/train.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "print('os')\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print output\n",
    "def out(preds):\n",
    "    output = pd.DataFrame({'PassengerId': test.PassengerId,'Survived': preds})\n",
    "    output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "",
    "_uuid": ""
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "gender_submission = pd.read_csv(\"../input/titanic/gender_submission.csv\")\n",
    "test = pd.read_csv(\"../input/titanic/test.csv\")\n",
    "train = pd.read_csv(\"../input/titanic/train.csv\")\n",
    "rstate=30\n",
    "t_size=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data preprocessor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def process_data(data):\n",
    "    encode = LabelEncoder()\n",
    "    ss=StandardScaler()\n",
    "    encode_features=['Sex','Cabin']\n",
    "    data.SibSp=data.SibSp.fillna(0)+data.Parch.fillna(0)\n",
    "    #Sib_data.SibSp='SibPa'\n",
    "    embarked_encode={'S':1,'C':3,'Q':2,'N':0}\n",
    "    name_encoded={ 'Don':0, 'Rev':0, 'Sir':0, 'Capt':0, 'Jonkheer':0, 'Major':1, 'Col':1, 'Dr':2, 'Master':3, 'Mr':4, 'Miss':5, 'Mrs':6, 'Mme':7, 'Mlle':7, 'the Countess':7, 'Lady':7 ,'Ms':7}\n",
    "    data.Embarked=[embarked_encode[x] for x in data.Embarked.fillna('N')]\n",
    "    data.Name=[name_encoded.get(y,0) for y in data.Name.apply(lambda x:x.split(',')[1].split('.')[0].strip())]\n",
    "    data_updated=data[data.columns.drop(['Parch','Ticket','PassengerId'])]\n",
    "    #data_updated=data_updated[data_updated.columns.drop('Embarked')].join(data_updated.Embarked.fillna('N'))\n",
    "    data_updated=data_updated[data_updated.columns.drop('Age')].join(data_updated.Age.fillna(0))\n",
    "    data_updated.Cabin=data_updated.Cabin.fillna('U').apply(lambda x:x[0])\n",
    "    data_updated= data_updated[data_updated.columns.drop(encode_features)].join(data_updated[encode_features].apply(encode.fit_transform))\n",
    "    data_updated.Cabin=ss.fit_transform(data_updated.Cabin.values.reshape(-1,1))\n",
    "    data_updated.Name=ss.fit_transform(data_updated.Name.values.reshape(-1,1))\n",
    "    data_updated.Embarked=ss.fit_transform(data_updated.Embarked.values.reshape(-1,1))\n",
    "    data_updated.SibSp=ss.fit_transform(data_updated.SibSp.values.reshape(-1,1))\n",
    "    data_updated.Fare=ss.fit_transform(data_updated.Fare.fillna(data_updated.Fare.mean()).values.reshape(-1,1))\n",
    "    data_updated.Age=ss.fit_transform(data_updated.Age.values.reshape(-1,1))\n",
    "    return data_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Cabin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.391348</td>\n",
       "      <td>0.059160</td>\n",
       "      <td>-0.502445</td>\n",
       "      <td>-0.581114</td>\n",
       "      <td>-0.102313</td>\n",
       "      <td>1</td>\n",
       "      <td>0.522067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.635926</td>\n",
       "      <td>0.059160</td>\n",
       "      <td>0.786845</td>\n",
       "      <td>1.938460</td>\n",
       "      <td>0.807492</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.917594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.622289</td>\n",
       "      <td>-0.560975</td>\n",
       "      <td>-0.488854</td>\n",
       "      <td>-0.581114</td>\n",
       "      <td>0.125138</td>\n",
       "      <td>0</td>\n",
       "      <td>0.522067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.635926</td>\n",
       "      <td>0.059160</td>\n",
       "      <td>0.420730</td>\n",
       "      <td>-0.581114</td>\n",
       "      <td>0.636903</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.917594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.391348</td>\n",
       "      <td>-0.560975</td>\n",
       "      <td>-0.486337</td>\n",
       "      <td>-0.581114</td>\n",
       "      <td>0.636903</td>\n",
       "      <td>1</td>\n",
       "      <td>0.522067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass      Name     SibSp      Fare  Embarked       Age  Sex  \\\n",
       "0         0       3 -0.391348  0.059160 -0.502445 -0.581114 -0.102313    1   \n",
       "1         1       1  1.635926  0.059160  0.786845  1.938460  0.807492    0   \n",
       "2         1       3  0.622289 -0.560975 -0.488854 -0.581114  0.125138    0   \n",
       "3         1       1  1.635926  0.059160  0.420730 -0.581114  0.636903    0   \n",
       "4         0       3 -0.391348 -0.560975 -0.486337 -0.581114  0.636903    1   \n",
       "\n",
       "      Cabin  \n",
       "0  0.522067  \n",
       "1 -1.917594  \n",
       "2  0.522067  \n",
       "3 -1.917594  \n",
       "4  0.522067  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_train=process_data(train)\n",
    "processed_test=process_data(test)\n",
    "processed_train_y=processed_train.Survived\n",
    "processed_train_x=processed_train[processed_train.columns.drop('Survived')]\n",
    "processed_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Cabin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>0.402263</td>\n",
       "      <td>0.016639</td>\n",
       "      <td>0.257307</td>\n",
       "      <td>0.163517</td>\n",
       "      <td>0.010539</td>\n",
       "      <td>-0.543351</td>\n",
       "      <td>-0.301116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.338481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.071031</td>\n",
       "      <td>0.065997</td>\n",
       "      <td>-0.549500</td>\n",
       "      <td>-0.157112</td>\n",
       "      <td>-0.361353</td>\n",
       "      <td>0.131900</td>\n",
       "      <td>0.746616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <td>0.402263</td>\n",
       "      <td>-0.071031</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.090879</td>\n",
       "      <td>0.129724</td>\n",
       "      <td>0.073551</td>\n",
       "      <td>0.010180</td>\n",
       "      <td>-0.778165</td>\n",
       "      <td>-0.092201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>0.016639</td>\n",
       "      <td>0.065997</td>\n",
       "      <td>0.090879</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.217138</td>\n",
       "      <td>-0.064701</td>\n",
       "      <td>-0.150584</td>\n",
       "      <td>-0.200988</td>\n",
       "      <td>0.012131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.257307</td>\n",
       "      <td>-0.549500</td>\n",
       "      <td>0.129724</td>\n",
       "      <td>0.217138</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.221226</td>\n",
       "      <td>0.135516</td>\n",
       "      <td>-0.182333</td>\n",
       "      <td>-0.523013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <td>0.163517</td>\n",
       "      <td>-0.157112</td>\n",
       "      <td>0.073551</td>\n",
       "      <td>-0.064701</td>\n",
       "      <td>0.221226</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.087085</td>\n",
       "      <td>-0.104057</td>\n",
       "      <td>-0.187015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.010539</td>\n",
       "      <td>-0.361353</td>\n",
       "      <td>0.010180</td>\n",
       "      <td>-0.150584</td>\n",
       "      <td>0.135516</td>\n",
       "      <td>-0.087085</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024978</td>\n",
       "      <td>-0.274458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>-0.543351</td>\n",
       "      <td>0.131900</td>\n",
       "      <td>-0.778165</td>\n",
       "      <td>-0.200988</td>\n",
       "      <td>-0.182333</td>\n",
       "      <td>-0.104057</td>\n",
       "      <td>0.024978</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.123076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin</th>\n",
       "      <td>-0.301116</td>\n",
       "      <td>0.746616</td>\n",
       "      <td>-0.092201</td>\n",
       "      <td>0.012131</td>\n",
       "      <td>-0.523013</td>\n",
       "      <td>-0.187015</td>\n",
       "      <td>-0.274458</td>\n",
       "      <td>0.123076</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Survived    Pclass      Name     SibSp      Fare  Embarked  \\\n",
       "Survived  1.000000 -0.338481  0.402263  0.016639  0.257307  0.163517   \n",
       "Pclass   -0.338481  1.000000 -0.071031  0.065997 -0.549500 -0.157112   \n",
       "Name      0.402263 -0.071031  1.000000  0.090879  0.129724  0.073551   \n",
       "SibSp     0.016639  0.065997  0.090879  1.000000  0.217138 -0.064701   \n",
       "Fare      0.257307 -0.549500  0.129724  0.217138  1.000000  0.221226   \n",
       "Embarked  0.163517 -0.157112  0.073551 -0.064701  0.221226  1.000000   \n",
       "Age       0.010539 -0.361353  0.010180 -0.150584  0.135516 -0.087085   \n",
       "Sex      -0.543351  0.131900 -0.778165 -0.200988 -0.182333 -0.104057   \n",
       "Cabin    -0.301116  0.746616 -0.092201  0.012131 -0.523013 -0.187015   \n",
       "\n",
       "               Age       Sex     Cabin  \n",
       "Survived  0.010539 -0.543351 -0.301116  \n",
       "Pclass   -0.361353  0.131900  0.746616  \n",
       "Name      0.010180 -0.778165 -0.092201  \n",
       "SibSp    -0.150584 -0.200988  0.012131  \n",
       "Fare      0.135516 -0.182333 -0.523013  \n",
       "Embarked -0.087085 -0.104057 -0.187015  \n",
       "Age       1.000000  0.024978 -0.274458  \n",
       "Sex       0.024978  1.000000  0.123076  \n",
       "Cabin    -0.274458  0.123076  1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Plotting\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "#confusion_matrix()\n",
    "processed_train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model iterator\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def model_check(est,train_x,train_y,test_x,test_y):\n",
    "    model=rfc(n_estimators=est,random_state=rstate)\n",
    "    model.fit(train_x,train_y)\n",
    "    preds=model.predict(test_x)\n",
    "    return roc_auc_score(test_y,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data\n",
    "def split(X,Y):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    return train_test_split(X,Y,test_size=t_size,random_state=rstate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{100: 0.7832175925925925, 200: 0.7939814814814815, 300: 0.7908564814814815, 400: 0.7939814814814815, 500: 0.7939814814814815, 550: 0.7939814814814815, 600: 0.7954861111111111, 650: 0.7862268518518519, 750: 0.7893518518518519}\n"
     ]
    }
   ],
   "source": [
    "train_x,valid_x,train_y,valid_y=split(processed_train_x,processed_train_y)\n",
    "mea_dict={}\n",
    "for i in (100,200,300,400,500,550,600,650,750):\n",
    "    mea_dict[i]=model_check(i,train_x,train_y,valid_x,valid_y)\n",
    "print(mea_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=30, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest Model\n",
    "model_rf=rfc(n_estimators=100,random_state=rstate)\n",
    "model_rf.fit(processed_train_x,processed_train_y)\n",
    "\n",
    "#preds=model_rf.predict(processed_test)\n",
    "#out(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's binary_logloss: 0.475961\n",
      "[2]\tvalid_0's binary_logloss: 0.465167\n",
      "[3]\tvalid_0's binary_logloss: 0.467138\n",
      "[4]\tvalid_0's binary_logloss: 0.465885\n",
      "[5]\tvalid_0's binary_logloss: 0.462099\n",
      "[6]\tvalid_0's binary_logloss: 0.462972\n",
      "[7]\tvalid_0's binary_logloss: 0.462057\n",
      "[8]\tvalid_0's binary_logloss: 0.460788\n",
      "[9]\tvalid_0's binary_logloss: 0.462444\n"
     ]
    }
   ],
   "source": [
    "#LightGBM Model\n",
    "import lightgbm as lgb\n",
    "train_x,valid_x,train_y,valid_y=split(processed_train_x,processed_train_y)\n",
    "Dtrain=lgb.Dataset(train_x,train_y)\n",
    "Dvalid=lgb.Dataset(valid_x,valid_y)\n",
    "params={'num_leaves':'70',\n",
    "        'max_depth':'7',\n",
    "        'objective':'binary',\n",
    "        'boosting':'rf',\n",
    "        'bagging_freq':1,\n",
    "        'bagging_fraction':'0.9',\n",
    "        'metric': 'binary_logloss'}\n",
    "gbm = lgb.train(params,\n",
    "                Dtrain,\n",
    "                num_boost_round=9,\n",
    "                valid_sets=Dvalid  # eval training data\n",
    "                )\n",
    "preds_gbm=list(map(lambda x: 1 if x>0.5 else 0,gbm.predict(processed_test)))\n",
    "#print(preds_gbm)\n",
    "#out(preds_gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7413369103509948\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_absolute_error as mea\n",
    "model_nb=GaussianNB()\n",
    "train_x,valid_x,train_y,valid_y=split(processed_train_x,processed_train_y)\n",
    "model_nb.fit(train_x,train_y)\n",
    "y_pred=model_nb.predict(valid_x)\n",
    "print(roc_auc_score(y_pred,valid_y))\n",
    "#model_nb.fit(processed_train_x,processed_train_y)\n",
    "#preds_nb=model_nb.predict(processed_test)\n",
    "#out(preds_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.197531\n",
      "Will train until validation_0-error hasn't improved in 15 rounds.\n",
      "[1]\tvalidation_0-error:0.222222\n",
      "[2]\tvalidation_0-error:0.197531\n",
      "[3]\tvalidation_0-error:0.222222\n",
      "[4]\tvalidation_0-error:0.197531\n",
      "[5]\tvalidation_0-error:0.222222\n",
      "[6]\tvalidation_0-error:0.197531\n",
      "[7]\tvalidation_0-error:0.222222\n",
      "[8]\tvalidation_0-error:0.197531\n",
      "[9]\tvalidation_0-error:0.222222\n",
      "[10]\tvalidation_0-error:0.197531\n",
      "[11]\tvalidation_0-error:0.197531\n",
      "[12]\tvalidation_0-error:0.197531\n",
      "[13]\tvalidation_0-error:0.197531\n",
      "[14]\tvalidation_0-error:0.197531\n",
      "[15]\tvalidation_0-error:0.197531\n",
      "Stopping. Best iteration:\n",
      "[0]\tvalidation_0-error:0.197531\n",
      "\n",
      "0.7678703021370671\n",
      "[0]\tvalidation_0-error:0.216418\n",
      "Will train until validation_0-error hasn't improved in 15 rounds.\n",
      "[1]\tvalidation_0-error:0.227612\n",
      "[2]\tvalidation_0-error:0.216418\n",
      "[3]\tvalidation_0-error:0.227612\n",
      "[4]\tvalidation_0-error:0.216418\n",
      "[5]\tvalidation_0-error:0.227612\n",
      "[6]\tvalidation_0-error:0.216418\n",
      "[7]\tvalidation_0-error:0.227612\n",
      "[8]\tvalidation_0-error:0.216418\n",
      "[9]\tvalidation_0-error:0.227612\n",
      "[10]\tvalidation_0-error:0.216418\n",
      "[11]\tvalidation_0-error:0.216418\n",
      "[12]\tvalidation_0-error:0.216418\n",
      "[13]\tvalidation_0-error:0.216418\n",
      "[14]\tvalidation_0-error:0.216418\n",
      "[15]\tvalidation_0-error:0.216418\n",
      "Stopping. Best iteration:\n",
      "[0]\tvalidation_0-error:0.216418\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#XGB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "model_xgb = XGBClassifier(n_estimators=180,random_state=rstate,learning_rate=0.01)\n",
    "train_x,valid_x,train_y,valid_y=split(processed_train_x,processed_train_y)\n",
    "valid_x,test_x,valid_y,test_y=split(valid_x,valid_y)\n",
    "model_xgb.fit(train_x, train_y,early_stopping_rounds=15,eval_set=[(test_x,test_y)])\n",
    "y_preds_x=model_xgb.predict(valid_x)\n",
    "print(roc_auc_score(y_preds_x,valid_y))\n",
    "\n",
    "#creating full model\n",
    "train_x,valid_x,train_y,valid_y=split(processed_train_x,processed_train_y)\n",
    "model_xgb.fit(train_x, train_y,early_stopping_rounds=15,eval_set=[(valid_x,valid_y)])\n",
    "preds_xb=model_xgb.predict(processed_test)\n",
    "out(preds_xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7988764044943819\n",
      "0.7985074626865671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#MLP\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "train_x,valid_x,train_y,valid_y=split(processed_train_x,processed_train_y)\n",
    "model_MLP=MLPClassifier()\n",
    "model_MLP.fit(train_x,train_y)\n",
    "preds_mlp_y=model_MLP.predict(valid_x)\n",
    "print(roc_auc_score(preds_mlp_y,valid_y))\n",
    "print(model_MLP.score(valid_x,valid_y))\n",
    "\n",
    "#predictions\n",
    "preds_mlp=model_MLP.predict(processed_test)\n",
    "out(preds_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7924731182795699\n"
     ]
    }
   ],
   "source": [
    "#KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "train_x,valid_x,train_y,valid_y=split(processed_train_x,processed_train_y)\n",
    "model_KN=KNeighborsClassifier()\n",
    "model_KN.fit(train_x,train_y)\n",
    "preds_kn_y=model_KN.predict(valid_x)\n",
    "print(roc_auc_score(preds_kn_y,valid_y))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
